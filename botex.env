# botex.env - Configuration for botex experiment with llama.cpp

# oTree configuration
OTREE_SESSION_CONFIG=social_influence_task
OTREE_NPARTICIPANTS=5
OTREE_NHUMANS=0

# Skip health check (needed for llama.cpp)
BOTEX_SKIP_HEALTH_CHECK=1

# Path to model file (for reference only - actual path is passed to the server binary)
LLAMACPP_LOCAL_LLM_PATH=models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf

# For cloud models (optional)
# API_KEY=your_api_key_here

# llamacpp configuration
LLM_MODEL="llamacpp"
API_BASE="http://localhost:8080"

OTREE_AUTH_LEVEL=DEMO
OTREE_ADMIN_PASSWORD=StUJfPQdcoWRtnxC
OTREE_PRODUCTION=1
OTREE_SECRET_KEY=h8J3fT9mN7vX2cQ5qR6tY4wZ8bE3sL7dB1gH5jM2nB6vC9xF4
OTREE_REST_KEY=dcd5f85871fafbc2a86b64be38370e5af64ab12d31e6a4bcc3560083e1a65a0d
